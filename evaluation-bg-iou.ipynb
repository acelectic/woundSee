{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "# \"\" = CPU\n",
    "# \"0\" = GPU_0\n",
    "# \"1\" = GPU_1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; \n",
    "# print( 'CUDA Version =', os.environ['CUDA_VERSION'] )\n",
    "\n",
    "import sys\n",
    "print( 'Python Version =', sys.version.split()[0] )\n",
    "\n",
    "import tensorflow as tf\n",
    "print( 'Tensorflow Version =',tf.__version__)\n",
    "\n",
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, '../..')\n",
    "from os.path import join\n",
    "from utils_1 import *\n",
    "import shutil\n",
    "import gc\n",
    "from inspect import getsource\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# from tqdm import tqdm as tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "import pprint\n",
    "import math\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log(file):\n",
    "    def write(msg):\n",
    "        with open( file, 'a' ) as f:\n",
    "            f.write( '%s\\n' % msg )\n",
    "    \n",
    "    with open(file, 'w'):\n",
    "        pass\n",
    "    \n",
    "    return write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(y_true, y_pred):\n",
    "    from tensorflow.keras import backend as K\n",
    "    \n",
    "    y_pred    = K.argmax( y_pred, axis=-1 )\n",
    "    y_pred    = K.one_hot(K.cast(y_pred, 'int32'), num_classes=6)\n",
    "    y_true_f  = K.flatten( y_true[...,1:] )\n",
    "    y_pred_f  = K.flatten( y_pred[...,1:] )\n",
    "    intersect = K.sum(y_true_f * y_pred_f, axis=-1)\n",
    "    union     = K.sum(y_true_f + y_pred_f, axis=-1) - intersect\n",
    "    if union == 0:\n",
    "        return 1.\n",
    "    return intersect / union\n",
    "\n",
    "\n",
    "def dice(y_true, y_pred ):\n",
    "    from tensorflow.keras import backend as K\n",
    "    y_pred    = K.argmax( y_pred, axis=-1 )\n",
    "    y_pred    = K.one_hot(K.cast(y_pred, 'int32'), num_classes=6)\n",
    "    y_true_f  = K.flatten( y_true[...,1:] )\n",
    "    y_pred_f  = K.flatten( y_pred[...,1:] )\n",
    "    intersect = K.sum(y_true_f * y_pred_f, axis=-1)\n",
    "    denom     = K.sum(y_true_f + y_pred_f, axis=-1)\n",
    "    if denom == 0:\n",
    "        return 1.\n",
    "    return 2. * intersect / denom\n",
    "\n",
    "\n",
    "def cate(y_true, y_pred ):\n",
    "    from tensorflow.keras.metrics import categorical_accuracy\n",
    "    return categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    from tensorflow.keras import backend as K\n",
    "    \n",
    "    def dice(y_true, y_pred):\n",
    "        intersection = K.sum(y_true * y_pred, axis=axis)\n",
    "        denom        = K.sum(y_true, axis=axis) + K.sum(y_pred, axis=axis)\n",
    "        \n",
    "        return (2. * intersection + smooth) / (denom + smooth)\n",
    "    \n",
    "    def iou(y_true, y_pred):\n",
    "        intersection = K.sum(y_true * y_pred, axis=axis)\n",
    "        union        = K.sum(y_true, axis=axis) + K.sum(y_pred, axis=axis) - intersection\n",
    "        \n",
    "        return ( intersection + smooth ) / ( union + smooth )\n",
    "    \n",
    "    axis   = [1,2,3]\n",
    "    smooth = 1\n",
    "    gamma  = 1.\n",
    "    loss   = 1 - dice( y_true, y_pred )\n",
    "    return K.pow( loss, gamma )\n",
    "\n",
    "\n",
    "def get_model(model_path):\n",
    "    from tensorflow.keras.models import load_model\n",
    "    return load_model( model_path ,custom_objects={ 'loss_func':loss, 'loss': loss, 'dice':dice , 'iou': iou, 'cate': cate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x( path ):\n",
    "    def get_x_rgb( path ):\n",
    "        rgb = read_image( path, 'rgb' )\n",
    "        return rgb / 255\n",
    "\n",
    "    get_x = get_x_rgb\n",
    "    x = np.array( get_x(path) ).astype( np.float32 )\n",
    "    return x\n",
    "\n",
    "def get_y( path ):\n",
    "    grayscale = read_image( path, 'gray' ) / color\n",
    "    layers = [  (grayscale == i) + [0] for i in range(0, num_classes) ]\n",
    "      \n",
    "    return np.stack( layers, axis=2 ).astype( np.float32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou( y_true, y_pred ):\n",
    "    y_pred = y_pred[...,1:].flatten()\n",
    "    y_true = y_true[...,1:].flatten()\n",
    "    \n",
    "    intersection = np.sum( y_pred * y_true )\n",
    "    union = np.sum( y_pred ) + np.sum( y_true ) - intersection\n",
    "    \n",
    "    if union == 0.:\n",
    "        return 100.\n",
    "    \n",
    "    iou_score = intersection / union\n",
    "    return iou_score * 100\n",
    "\n",
    "\n",
    "def calculate_dice( y_true, y_pred ):\n",
    "    y_pred = y_pred[...,1:].flatten()\n",
    "    y_true = y_true[...,1:].flatten()\n",
    "    \n",
    "    intersection = np.sum( y_pred * y_true )\n",
    "    denom        = np.sum( y_pred ) + np.sum( y_true )\n",
    "    \n",
    "    if denom == 0.:\n",
    "        return 100.\n",
    "    \n",
    "    dice_score = 2. * intersection / denom\n",
    "    return dice_score * 100\n",
    "    \n",
    "    \n",
    "def calculate_region_size_error( y_true, y_pred ):\n",
    "    y_pred = y_pred[...,1:].flatten()\n",
    "    y_true = y_true[...,1:].flatten()\n",
    "    \n",
    "    gt = np.sum(y_true)\n",
    "    cs = np.sum(y_pred)\n",
    "    \n",
    "    if gt == 0.:\n",
    "        return 100.\n",
    "    \n",
    "    region_size_error = abs( gt - cs ) / gt\n",
    "    return region_size_error * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dir(Experiment_DIR):\n",
    "    path = os.path.join( Experiment_DIR, 'detail.txt' )\n",
    "    with open( path , 'r' ) as file:\n",
    "        data = file.read()\n",
    "    \n",
    "    desc_index = data.find('Description:')\n",
    "    desc = data[desc_index: data.find( '\\n', desc_index)].split(\" \")[-1]\n",
    "    return desc\n",
    "\n",
    "\n",
    "def get_history( dirs, Experiment_DIR ):\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    iou_s = []\n",
    "    val_iou_s = []\n",
    "    for fold in dirs:\n",
    "        fold_DIR = os.path.join( Experiment_DIR, fold )\n",
    "        history_path = os.path.join( fold_DIR, 'history.npy' )\n",
    "        \n",
    "        if not is_exists(history_path):\n",
    "            raise FileNotFoundError(history_path)\n",
    "        \n",
    "        history = np.load( history_path, allow_pickle=True )\n",
    "        logs = history.item()\n",
    "        \n",
    "        losses.append( logs['loss'] )\n",
    "        val_losses.append( logs['val_loss'] )\n",
    "        \n",
    "        iou_s.append( logs['iou'] )\n",
    "        val_iou_s.append( logs['val_iou'] )\n",
    "    \n",
    "    losses     = np.array( losses ).T\n",
    "    val_losses = np.array(val_losses).T\n",
    "    iou_s      = np.array( iou_s ).T\n",
    "    val_iou_s  = np.array( val_iou_s ).T\n",
    "    \n",
    "    return ( losses, iou_s ) , ( val_losses, val_iou_s )\n",
    "\n",
    "def window_generator( windows, b_size ):\n",
    "    def load( windows ):\n",
    "        x = np.asarray( windows ).astype(np.float32)\n",
    "        return x\n",
    "    \n",
    "    L = len(windows)\n",
    "    \n",
    "    while True:\n",
    "        batch_start = 0\n",
    "        batch_end = b_size\n",
    "        \n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "            x     = load( windows[batch_start:limit] )\n",
    "            yield x\n",
    "            batch_start += b_size\n",
    "            batch_end   += b_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "def plot_confusion_matrix_custom(confusion_matrix_all, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          figsize=(8,8)):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix_all\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "#     print(cm)\n",
    "    tmp = np.reshape(cm, -1)\n",
    "    tmp = [0 if math.isnan(x) else x for x in tmp]\n",
    "    tmp = np.reshape(tmp, cm.shape)\n",
    "    cm = tmp.copy()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    \n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelGray2Color(image, color_class):\n",
    "#     print(\"unique color: \",np.unique(image))\n",
    "    # wound tissued\n",
    "    label_color = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "    label_color[image == 0]    = color_class[0]\n",
    "    label_color[image == color*1] = color_class[1]\n",
    "    label_color[image == color*2] = color_class[2]\n",
    "    label_color[image == color*3] = color_class[3]\n",
    "    label_color[image == color*4] = color_class[4]\n",
    "\n",
    "    # wound closed\n",
    "#     label_color = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "#     label_color[image == 0]    = color_class[0]\n",
    "#     label_color[image == color*1] = color_class[1]\n",
    "    return label_color\n",
    "\n",
    "def plot_sample(title, original, label, predict):\n",
    "    \n",
    "    raw_label = label.copy()\n",
    "    raw_predict = predict.copy()\n",
    "    \n",
    "    def mergeLabelPred( label, predict):\n",
    "        print(\"shape\", label.shape, predict.shape)\n",
    "        label_color = np.zeros((label.shape[0], label.shape[1], 3), dtype=np.uint8)\n",
    "        label[label > 0] = 1\n",
    "        predict[predict > 0] = 1\n",
    "#         print(label.shape)\n",
    "#         print(np.unique(label))\n",
    "        label_color[label > 0] += 80\n",
    "        label_color[predict > 0] += 160\n",
    "    \n",
    "#         print(label_color.shape)\n",
    "#         print(np.unique(label_color))\n",
    "        label_color[label_color == 80]  = 255\n",
    "        label_color[label_color == 160] = 180\n",
    "        label_color[label_color == 240] = 50\n",
    "\n",
    "        return label_color\n",
    "    \n",
    "    f, (a1, a2, a3, a4, a5) = plt.subplots( 1, 5, figsize=(15,8) )\n",
    "    f.suptitle( title )\n",
    "    a1.set_title('Original')\n",
    "    a1.imshow( original )\n",
    "    \n",
    "    a2.set_title('Label')\n",
    "    label = labelGray2Color(label, color_class)\n",
    "    im2 = a2.imshow(label)\n",
    "#     a2.figure.colorbar(im2, ax=a2) \n",
    "    \n",
    "    a3.set_title('Predict')\n",
    "    predict = labelGray2Color(predict, color_class)\n",
    "    im3 = a3.imshow( predict)\n",
    "#     a3.figure.colorbar(im3, ax=a3)\n",
    "    \n",
    "    a4.set_title('pred vs label IoU')\n",
    "    mergeLabelPred = mergeLabelPred( raw_label, raw_predict)\n",
    "    im3 = a4.imshow( mergeLabelPred )\n",
    "    \n",
    "#     print(color_class)\n",
    "    a5.set(yticks=np.arange(6),\n",
    "           yticklabels= tmp_labels,\n",
    "           title='Class Color')\n",
    "    a5.get_xaxis().set_ticks([])\n",
    "    re_color_class = np.reshape(color_class, (6, 1, 3))\n",
    "#     print(re_color_class)\n",
    "    a5.imshow(re_color_class, interpolation='nearest')\n",
    "    \n",
    "    return f\n",
    "\n",
    "def confusion2string(title, confusion, class_names, normalize=False):\n",
    "#     print(confusion.shape)\n",
    "#     print(confusion)\n",
    "#     print(zip(*class_names))\n",
    "   \n",
    "    \n",
    "    temp_lines = ['{}:'.format(title),\n",
    "                 \"%15s %15s %15s %15s %15s %15s\" % ('actual\\\\predict', *class_names)]\n",
    "    if normalize == True:\n",
    "        cm = confusion.copy()\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        tmp = np.reshape(cm, -1)\n",
    "        tmp = [0. if math.isnan(x) else x if x != 0. else -1 for x in tmp]\n",
    "        tmp = np.reshape(tmp, confusion.shape)\n",
    "        confusion = tmp\n",
    "        for i, data in enumerate(confusion):\n",
    "#             temp_lines += [\"%15s %15s %15s %15s %15s %15s %15s\" % (class_names[i], *[\"{:,}\".format(round(x, 2)) if x > 0 else \"-\" for x in data])]\n",
    "            temp_lines += [\"%15s %15s %15s %15s %15s %15s\" % (class_names[i], *[\"{:,.3f}\".format(x) for x in data])]\n",
    "#             temp_lines += [\"%15s %15s %15s\" % (class_names[i], *[\"{:,.3f}\".format(x) for x in data])]\n",
    "    \n",
    "    else:\n",
    "        for i, data in enumerate(confusion):\n",
    "            temp_lines += [\"%15s %15s %15s %15s %15s %15s\" % (class_names[i], *[\"{:,}\".format(int(x)) for x in data])]\n",
    "#             temp_lines += [\"%15s %15s %15s\" % (class_names[i], *[\"{:,}\".format(int(x)) for x in data])]\n",
    "\n",
    "    return '\\n'.join(temp_lines) + \"\\n\\n\"\n",
    "\n",
    "def genReport(non_bg_iou_list, iou_list, dice_list, rse_list, time_list, confusion_matrix_all, class_names, image_names, model_path, normalize=0):\n",
    "    log = \"model_path : %s \\n\\n\" % (model_path)\n",
    "    log += '\\t'.join(\n",
    "            [ \"%s\" % \"image_name\"] + list( map(lambda x: '%5s' % x, [\"non_bg_iou\", \"IoU\", \"Dice\", \"RSE\", \"Time\"]) ) \n",
    "            ) + \"\\n\"\n",
    "    for i in range(len(iou_list)):\n",
    "        non_bg_iou, iou_, dice_, rse_, time_, image_name = non_bg_iou_list[i], iou_list[i], dice_list[i], rse_list[i], time_list[i], image_names[i]\n",
    "        log += '\\t'.join(\n",
    "                [ \"%s\" % image_name] + list( map(lambda x: '%-3.2f' % x, [non_bg_iou, iou_, dice_, rse_, time_]) ) \n",
    "                ) + \"\\n\"\n",
    "    \n",
    "    mean_iou       = np.mean( iou_list )\n",
    "    mean_dice      = np.mean( dice_list )\n",
    "    mean_rse       = np.mean( rse_list )\n",
    "    mean_bg_iou    = np.mean( non_bg_iou_list )\n",
    "    \n",
    "    log += \"\\n\" + '\\n'.join([\"{}\\t{:.4f}\".format(x[0], x[1]) for x in \n",
    "                             list(zip([\"mean_bg_iou\", \"mean_iou\", \"mean_dice\", \"mean_rse\"],[mean_bg_iou, mean_iou, mean_dice, mean_rse]))]) + \"\\n\\n\"\n",
    "    \n",
    "    summary_confusion = confusion2string(title=\"Summary Confusion Matrix\", confusion=\n",
    "                           confusion_matrix_all, class_names=class_names)\n",
    "    log += summary_confusion\n",
    "    \n",
    "    summary_confusion_normalize = confusion2string(title=\"Summary Confusion Matrix Normalize\", confusion=\n",
    "                           confusion_matrix_all, class_names=class_names, normalize=True)\n",
    "    log += summary_confusion_normalize\n",
    "    \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sample_sub( model, f_path, l_path ):\n",
    "    tic = time.time()\n",
    "    f_img = get_x(f_path)\n",
    "    l_img = get_y(l_path)\n",
    "    \n",
    "    f_windows = [ f_img ]\n",
    "    win_gen = window_generator( f_windows, b_size )\n",
    "    \n",
    "    y_pred = model.predict_generator(\n",
    "        generator=win_gen,\n",
    "        steps=len(f_windows) / b_size\n",
    "    )\n",
    "    y_ori_pred = y_pred.squeeze()\n",
    "    \n",
    "    y_pred = np.eye( num_classes )[y_ori_pred.argmax(axis=-1 )]\n",
    "    y_true = l_img\n",
    "    \n",
    "    iou_  = calculate_iou( y_true, y_pred )\n",
    "    dice_ = calculate_dice( y_true, y_pred )\n",
    "    rse_  = calculate_region_size_error( y_true, y_pred )\n",
    "    confusion   = confusion_matrix( y_true.argmax(axis=-1 ).flatten(), y_pred.argmax(axis=-1 ).flatten(), labels=[0,1,2,3,4] )\n",
    "    \n",
    "    segmented = y_ori_pred.argmax(axis=-1 ) * color\n",
    "    \n",
    "    def calculate_non_bg_iou( y_true, y_pred ):\n",
    "        y_pred = y_pred.flatten()\n",
    "        y_true = y_true.flatten()\n",
    "        y_pred[y_pred > 0] = 1 \n",
    "        y_true[y_true > 0] = 1\n",
    "\n",
    "        intersection = np.sum( y_pred * y_true )\n",
    "        union = np.sum( y_pred ) + np.sum( y_true ) - intersection\n",
    "\n",
    "        if union == 0.:\n",
    "            return 100.\n",
    "\n",
    "        iou_score = intersection / union\n",
    "        return iou_score * 100\n",
    "    \n",
    "    tmp_l_img = l_img.argmax(axis=-1 ) * 51\n",
    "    non_bg_iou = calculate_non_bg_iou(tmp_l_img, segmented)\n",
    "    \n",
    "    \n",
    "    toc = time.time()\n",
    "    return iou_, dice_, rse_, segmented, confusion, toc - tic, non_bg_iou\n",
    "\n",
    "def evaluate(model, sub_original_image_paths, sub_label_image_paths,\n",
    "             evaluate_dir, evaluate_image_dir, evaluate_fig_dir, \n",
    "             log_name, model_path, verbose=0, showfig=0):\n",
    "\n",
    "    if model == None:\n",
    "        pprint.pprint(evaluate_image_dir)\n",
    "        return\n",
    "    \n",
    "    tic           = time.time()\n",
    "    temp_sort_iou = {}\n",
    "    iou_list      = []\n",
    "    dice_list     = []\n",
    "    rse_list      = []\n",
    "    time_list     = []\n",
    "    image_names   = []\n",
    "    non_bg_iou_list = []\n",
    "    confusion_matrix_all= np.zeros(shape=(num_classes, num_classes))\n",
    "    sengmented_images   = []\n",
    "    \n",
    "    try:\n",
    "        flod_number = short_model_path.split(os.sep)[2]\n",
    "#         print(flod_number)\n",
    "        flod_number = int(flod_number)\n",
    "    except:\n",
    "        flod_number = \"eval\"\n",
    "    \n",
    "#     for i in tqdm( range(num_sub_original_images), desc='Sub-Image:' ):\n",
    "    tmp_index = 1\n",
    "    for i in range(num_sub_original_images):\n",
    "        original_img_path = sub_original_image_paths[i]\n",
    "        label_img_path = sub_label_image_paths[i]\n",
    "  \n",
    "        iou_, dice_, rse_, segmented, con, time_, non_bg_iou = evaluate_sample_sub(model, original_img_path, label_img_path)\n",
    "    \n",
    "#         new_image_name = \"{}-IoU-{:0.4f}.png\".format(str(tmp_index).zfill(4), iou_)\n",
    "        new_image_name = \"IoU-{:0.10f}.png\".format( iou_)\n",
    "        temp_sort_iou[new_image_name] = [new_image_name, original_img_path, label_img_path, iou_, dice_, rse_, segmented, con, time_, non_bg_iou]\n",
    "        \n",
    "        tmp_index += 1\n",
    "        \n",
    "#     pprint.pprint(temp_sort_iou)\n",
    "    tmp_sort = sorted(temp_sort_iou.items(), key=lambda x: x[1][3], reverse=True)\n",
    "    _, full_sort = zip(*tmp_sort)\n",
    "    for image_name, original_img_path, label_img_path, iou_, dice_, rse_, segmented, confusion, time_, non_bg_iou in full_sort:\n",
    "#         mean_iou       = np.mean( iou_list )\n",
    "#         mean_dice      = np.mean( dice_list )\n",
    "#         mean_rse       = np.mean( rse_list )\n",
    "        non_bg_iou_list.append(non_bg_iou)\n",
    "        iou_list.append(iou_)\n",
    "        dice_list.append(dice_)\n",
    "        rse_list.append(rse_)\n",
    "        sengmented_images.append(segmented)\n",
    "        time_list.append(time_)\n",
    "        image_names.append(image_name)\n",
    "        confusion_matrix_all += con\n",
    "\n",
    "    log = genReport(non_bg_iou_list, iou_list, dice_list, rse_list, time_list, confusion_matrix_all, class_names, image_names, model_path )\n",
    "#     print(log)\n",
    "    with open(os.path.join(log_name), 'a+') as f:\n",
    "        f.write(log)\n",
    "\n",
    "    tmp_key = [x[0] for x in tmp_sort[:10]] + [x[0] for x in tmp_sort[-10:]]\n",
    "#     print(len(tmp_key))\n",
    "    set_key = ()\n",
    "    for key in tmp_key:\n",
    "        if not key in set_key:\n",
    "            set_key += (key,)\n",
    "#     print(len(set_key))\n",
    "    new_sort = [temp_sort_iou[key] for key in set_key]\n",
    "#     Save image\n",
    "    tmp_index = 1\n",
    "    for image_name, original_img_path, label_img_path, iou_, dice_, rse_, segmented, confusion, time_, non_bg_iou in new_sort:\n",
    "        \n",
    "        new_image_name = \"{}-IoU-{:0.6f}.png\".format(str(tmp_index).zfill(4), iou_)\n",
    "#         new_image_name = image_name\n",
    "        \n",
    "        if verbose == True:\n",
    "            \n",
    "#             sub_fig_dir = os.path.join(evaluate_fig_dir, flod_number)\n",
    "#             os.makedirs(sub_fig_dir, exist_ok=True)\n",
    "            \n",
    "#             fig_image_path          = os.path.join(sub_fig_dir , flod_number + \"-\" +label_img_path.split(os.sep)[-1].replace(\".png\", \"_fig.png\"))\n",
    "#             print(fig_image_path)\n",
    "           \n",
    "            os.makedirs(evaluate_fig_dir, exist_ok=True)\n",
    "            fig_image_path          = os.path.join(evaluate_fig_dir , new_image_name)\n",
    "#             print(fig_image_path)\n",
    "\n",
    "            feature_img             = cv2.cvtColor(cv2.imread(original_img_path), cv2.COLOR_BGR2RGB)\n",
    "            label_image             = cv2.imread(label_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            tmp_title = [new_image_name] \n",
    "            tmp_title += [\"{: >12}:{:.2f}\".format(x[0], x[1]) for x in list(zip([\"iou\", \"mean_dice\", \"mean_rse\"], [iou_, dice_, rse_, time_]))]\n",
    "            title_fig = \"\".join(tmp_title)\n",
    "            fig_image               = plot_sample(title_fig, feature_img, label_image, segmented)\n",
    "            if SAVE_IMAGE == True:\n",
    "                fig_image.savefig(fig_image_path)\n",
    "#             predict_image_path      = os.path.join(evaluate_image_dir , label_img_path.split(os.sep)[-1])\n",
    "#             cv2.imwrite(predict_image_path, segmented)\n",
    "\n",
    "    #         sub_confusion = confusion2string(title=\"Sub-Confusion Matrix\", confusion= confusion, class_names=class_names)\n",
    "    #         log += sub_confusion\n",
    "        \n",
    "        if showfig == True:\n",
    "#             sub_image_dir = os.path.join(evaluate_image_dir, flod_number)\n",
    "#             os.makedirs(sub_image_dir, exist_ok=True)\n",
    "            \n",
    "#             fig_cufusion_path       = os.path.join(sub_image_dir , flod_number + \"-\" +label_img_path.split(os.sep)[-1].replace(\".png\", \"_confusion.png\"))\n",
    "#             print(fig_cufusion_path)\n",
    "\n",
    "            os.makedirs(evaluate_image_dir, exist_ok=True)\n",
    "            fig_cufusion_path       = os.path.join(evaluate_image_dir, new_image_name)\n",
    "#             print(fig_cufusion_path)\n",
    "            \n",
    "            fig_confusion           = plot_confusion_matrix_custom(confusion.astype(int), \n",
    "                                                            classes   = class_names,\n",
    "                                                            title     ='Confusion matrix :' + new_image_name,\n",
    "                                                            normalize = True,\n",
    "                                                            figsize   = (5,5))\n",
    "            if SAVE_IMAGE == True:\n",
    "                fig_confusion.savefig(fig_cufusion_path)\n",
    "        tmp_index += 1\n",
    "        \n",
    "        \n",
    "    \n",
    "   \n",
    "    \n",
    "    return non_bg_iou_list, iou_list, dice_list, rse_list, time_list, confusion_matrix_all, class_names, image_names, model_path, sengmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def eval_Kfold(dst_dir, experiments_dir, fold_dirs = None):\n",
    "    log_name            = os.path.join(dst_dir, \"log-{}.txt\".format(time.time()))\n",
    "    experiment_lists    = {}\n",
    "        \n",
    "    for fold_dir in fold_dirs:\n",
    "        full_experiment_dir = os.path.join(experiments_dir, fold_dir)\n",
    "        \n",
    "        evaluate_image_dir    = os.path.join(dst_dir, fold_dir, \"confusion_matrixs\")\n",
    "        evaluate_fig_dir      = os.path.join(dst_dir, fold_dir, \"images\")\n",
    "        experiment_model_path = os.path.join(experiment_dir, fold_dir, model_name + \"_model.h5\")\n",
    "        short_model_path      = experiment_model_path.replace(root, \"\")\n",
    "        \n",
    "        evaluate_result_dir = {\n",
    "                \"evaluate_dir\"             : dst_dir, \n",
    "                \"evaluate_image_dir\"       : evaluate_image_dir,\n",
    "                \"evaluate_fig_dir\"         : evaluate_fig_dir,\n",
    "                \"sub_original_image_paths\" : sub_original_image_paths,\n",
    "                \"sub_label_image_paths\"    : sub_label_image_paths,\n",
    "                \"log_name\"                 : log_name,\n",
    "                \"showfig\"                  : 1,\n",
    "                \"verbose\"                  : 1,\n",
    "                \"model_path\"               : short_model_path,\n",
    "        }\n",
    "        if os.path.isfile(experiment_model_path):\n",
    "            print(\"evaluate model: \", short_model_path)\n",
    "#             print(full_experiment_dir)\n",
    "#             print(evaluate_image_dir)\n",
    "#             print(evaluate_fig_dir)\n",
    "#             print()\n",
    "            gc.collect()\n",
    "            tmp_model = get_model(experiment_model_path)\n",
    "            log = short_model_path + \"\\n\\n\" \n",
    "            \n",
    "            with open(os.path.join(log_name), 'a+') as f:\n",
    "                f.write(log)\n",
    "            \n",
    "            non_bg_iou_list, iou_list, dice_list, rse_list, time_list, confusion_matrix_all, class_names, image_names, model_path, sengmented_images = evaluate(model=tmp_model, **evaluate_result_dir)\n",
    "            \n",
    "            experiment_lists[short_model_path] = dict( mean_iou             = np.mean( iou_list ),\n",
    "                                                       mean_dice            = np.mean( dice_list ),\n",
    "                                                       mean_rse             = np.mean( rse_list ),\n",
    "                                                       non_bg_iou_list = np.mean( non_bg_iou_list ))\n",
    "            \n",
    "            flod_number = short_model_path.split(os.sep)[2]\n",
    "            cfm_dir     = os.path.join(dst_dir, \"{}-confusion-normalize.png\".format(fold_dir))\n",
    "            \n",
    "            plot_confusion_matrix_custom(confusion_matrix_all.astype(int), classes=class_names, title='Confusion matrix, with normalization', normalize=True).savefig(cfm_dir)\n",
    "            \n",
    "            cfm_normalize_dir = os.path.join(dst_dir, \"{}-confusion.png\".format(fold_dir))\n",
    "            plot_confusion_matrix_custom(confusion_matrix_all.astype(int), classes=class_names, title='Confusion matrix, without normalization').savefig(cfm_normalize_dir)\n",
    "            \n",
    "            del tmp_model\n",
    "            gc.collect()\n",
    "        else:\n",
    "            print (\"File not exist :\", experiment_model_path.replace(root, \"\"))\n",
    "            \n",
    "    tmp_label = [\"non_bg_iou_list\", \"mean_iou\", \"mean_dice\", \"mean_rse\"]\n",
    "    \n",
    "    experiment_lists_sort_IoU = sorted(experiment_lists.items(), key=lambda item: item[1][\"mean_iou\"], reverse=True)\n",
    "#     pprint.pprint(experiment_lists_sort_IoU)        \n",
    "#     print(len(experiment_lists_sort_IoU))\n",
    "    log = \"%15s \\t\"% \"Experiment\" + \"\\t\".join([\"%15s \" % key for key in tmp_label]) + \"\\n\\n\"\n",
    "    for i in experiment_lists_sort_IoU:\n",
    "        log += \"%15s \\t\" % i[0] + \"\\t\".join([\"%15s \" % i[1][key] for key in tmp_label]) + \"\\n\"\n",
    "    print(log)\n",
    "    print(dst_dir)\n",
    "    with open(os.path.join(dst_dir, \"evaluate_experiment.txt\"), 'w+') as f:\n",
    "        print(\"create summary text\")\n",
    "  \n",
    "        f.write(log)\n",
    "       \n",
    "    return experiment_lists_sort_IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_height = 512\n",
    "window_width  = 512\n",
    "window_shape  = (window_height, window_width)\n",
    "color         = 63\n",
    "num_classes   = 5\n",
    "SAVE_IMAGE    = True\n",
    "\n",
    "color_class = [(0, 0, 0), (128, 0, 64), (230, 0, 0),  (255, 255, 102), (255, 153, 102)]\n",
    "tmp_labels  = ['background', 'necrosis', 'granulation', 'slough', 'epithelial']\n",
    "\n",
    "b_size              = 1\n",
    "# dataset_name        = \"wound_rajavithi\"\n",
    "dataset_name        = \"wound_rajavithi_korean_medetec\"\n",
    "\n",
    "experiment_number   = \"0000\"\n",
    "fold_dirs           = [\"2\",\"5\",\"8\"]\n",
    "# fold_dirs           = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "# fold_dirs           = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"]\n",
    "\n",
    "model_name          = \"best\"\n",
    "# testing_name        = \"training\"\n",
    "# testing_name        = \"testing_korean\"\n",
    "testing_name        = \"testing_korean_medetec\"\n",
    "# testing_name        = \"testing\"\n",
    "# testing_name        = \"testing_with_rotation\"\n",
    "# testing_name        = \"testing_with_rotation_color\"\n",
    "\n",
    "type_wound_name     = \"wound_tissue\"\n",
    "\n",
    "root                = os.path.join(\"..\", \"..\", \"..\", \"data\", dataset_name, \"wound_segmentation\", type_wound_name)\n",
    "experiment_dir      = os.path.join(root, \"experiments\", experiment_number) \n",
    "experiment_dir      = os.path.join(root, \"experiments\", experiment_number) \n",
    "\n",
    "src_dir             = os.path.join(root, testing_name)\n",
    "dst_dir             = os.path.join(root, \"evaluate\", experiment_number, testing_name)\n",
    "\n",
    "\n",
    "# log_name            = os.path.join(dst_dir, \"log-one-{}.txt\".format(time.time()))\n",
    "\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "sub_f_original_DIR = join(src_dir, 'feature')\n",
    "sub_l_original_DIR = join(src_dir, 'label')\n",
    "\n",
    "sub_paths = get_list_dir(sub_f_original_DIR)\n",
    "# sub_paths = sorted(sub_paths, key= lambda x: int(x.replace(\".png\", \"\")))\n",
    "\n",
    "sub_original_image_paths = [ join( sub_f_original_DIR, p) for p in sub_paths ]\n",
    "sub_label_image_paths    = [ join( sub_l_original_DIR, p) for p in sub_paths ]\n",
    "num_sub_original_images  = len(sub_original_image_paths)\n",
    "num_sub_original_images = 2\n",
    "# num_sub_original_images = 50\n",
    "\n",
    "class_names = ['background', 'necrosis', 'granulation', 'slough', 'epithelial']\n",
    "\n",
    "print(dst_dir)\n",
    "print(\"image size: \", num_sub_original_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### testing = rajavithi \n",
    "### fold 2, 5,8\n",
    "\n",
    "start_time = time.process_time()\n",
    "print(start_time)\n",
    "\n",
    "tmp_result = eval_Kfold(dst_dir, experiment_dir, fold_dirs)\n",
    "end_time = time.process_time()\n",
    "print(end_time)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing = rajavithi korean\n",
    "### fold 2, 5,8\n",
    "\n",
    "start_time = time.process_time()\n",
    "print(start_time)\n",
    "\n",
    "tmp_result = eval_Kfold(dst_dir, experiment_dir, fold_dirs)\n",
    "end_time = time.process_time()\n",
    "print(end_time)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing = rajavithi korean medetec\n",
    "### fold 2, 5,8\n",
    "\n",
    "start_time = time.process_time()\n",
    "print(start_time)\n",
    "\n",
    "tmp_result = eval_Kfold(dst_dir, experiment_dir, fold_dirs)\n",
    "end_time = time.process_time()\n",
    "print(end_time)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 0001 \n",
    "# fold 1\n",
    "start_time = time.process_time()\n",
    "print(start_time)\n",
    "\n",
    "tmp_result = eval_Kfold(dst_dir, experiment_dir, fold_dirs)\n",
    "end_time = time.process_time()\n",
    "print(end_time)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0002\n",
    "# fold 2-3\n",
    "start_time = time.process_time()\n",
    "print(start_time)\n",
    "\n",
    "tmp_result = eval_Kfold(dst_dir, experiment_dir, fold_dirs)\n",
    "end_time = time.process_time()\n",
    "print(end_time)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0003\n",
    "# fold 4-5\n",
    "start_time = time.process_time()\n",
    "print(start_time)\n",
    "\n",
    "tmp_result = eval_Kfold(dst_dir, experiment_dir, fold_dirs)\n",
    "end_time = time.process_time()\n",
    "print(end_time)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0006/\n",
    "# fold 6\n",
    "start_time = time.process_time()\n",
    "print(start_time)\n",
    "\n",
    "tmp_result = eval_Kfold(dst_dir, experiment_dir, fold_dirs)\n",
    "end_time = time.process_time()\n",
    "print(end_time)\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
